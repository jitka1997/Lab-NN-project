{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e8807d48-6746-4a68-bb12-137d326565a8",
      "metadata": {},
      "source": [
        "## Analysis of LMs with minicons\n",
        "\n",
        "For docs, see https://github.com/kanishkamisra/minicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a9875bc4-0578-4421-8e77-4919259c604d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import minicons #does it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00844fd6-a27e-40ce-806e-c96143e1e03f",
      "metadata": {},
      "source": [
        "### Sequence probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "98b82e42-256f-4702-84ae-0b1d5b33a056",
      "metadata": {},
      "outputs": [],
      "source": [
        "from minicons import scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7075f85c-982b-4f8a-8c6c-e6c82c805ab5",
      "metadata": {},
      "outputs": [],
      "source": [
        "#mlm_model = scorer.MaskedLMScorer('bert-base-uncased', 'cpu') ## if you use a masked LM, e.g. BERT\n",
        "ilm_model = scorer.IncrementalLMScorer('/Users/jitkamuravska/Neural-Networks/10/model/final', 'cpu') # if you use an autoregressive LM, e.g. GPT, Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f7b2a573-c873-49ba-b94e-f0bba695fa3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "stimuli1 = ['Die Schwestern backen.',\n",
        "           'Die Schwestern backt.']\n",
        "\n",
        "stimuli2 = ['The keys to the cabinet are on the table.',\n",
        "           'The keys to the cabinet is on the table.']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eaebf58-fd44-4930-b655-6e6293575122",
      "metadata": {},
      "source": [
        "We can calculate log-probabilities or surprisal (which is just negative log-probability):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a87136ae-069d-426b-80e7-96b4c6813c24",
      "metadata": {},
      "outputs": [],
      "source": [
        "## from minicons docs:\n",
        "# use sequence_score with different reduction options: \n",
        "# Sequence Surprisal - lambda x: -x.sum(0).item()\n",
        "# Sequence Log-probability - lambda x: x.sum(0).item()\n",
        "# Sequence Surprisal, normalized by number of tokens - lambda x: -x.mean(0).item()\n",
        "# Sequence Log-probability, normalized by number of tokens - lambda x: x.mean(0).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b372fcca-3dee-4e07-989d-11cc7d0b1bc4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[59.380279541015625, 58.838565826416016]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ilm_model.sequence_score(stimuli1, reduction = lambda x: -x.sum(0).item()) # surprisal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b169ca5c-d47e-44f6-9c72-75af6e75fb1d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[48.40953063964844, 48.65721893310547]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ilm_model.sequence_score(stimuli2, reduction = lambda x: -x.sum(0).item()) # surprisal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977e95eb-cff8-4d7a-8d67-bbfea8593632",
      "metadata": {},
      "source": [
        "We can also do the scoring conditioned on preceding words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "18e44ee0-8e4b-4fb9-845c-ea3f5988c304",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[15.027026176452637, 13.738594055175781]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ilm_model.conditional_score(['The brothers', 'The brothers'], \n",
        "                            ['sing.', 'dance.'], reduction = lambda x: -x.sum(0).item()) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17de3a86-82d6-4818-bb82-21b03a66326a",
      "metadata": {},
      "source": [
        "Finally, we can also get token-wise scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "73e1e65b-9cb5-4478-b3e5-08f89191b058",
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = ['The sisters bake.', 'The sisters bakes.']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e7a26978-7148-45fb-b71a-e05ecfa0a95a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('the', 0.0),\n",
              "  ('Ġsister', 8.05455493927002),\n",
              "  ('s', 7.318393230438232),\n",
              "  ('Ġb', 9.655799865722656),\n",
              "  ('ake', 9.099276542663574),\n",
              "  ('.', 2.6355857849121094)],\n",
              " [('the', 0.0),\n",
              "  ('Ġsister', 8.05455493927002),\n",
              "  ('s', 7.318393230438232),\n",
              "  ('Ġb', 9.655799865722656),\n",
              "  ('akes', 9.250178337097168),\n",
              "  ('.', 2.581660747528076)]]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ilm_model.token_score(sentences, surprisal = True) # for whatever reason, here the surprisal argument is different..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
